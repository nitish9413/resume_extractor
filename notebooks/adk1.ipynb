{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a613d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "# result = process_file(\"/home/ubuntu/nitish/resume_extractor/data/f32e881949c44afa91794d02dc6c2f46.pdf\")\n",
    "converter = DocumentConverter()\n",
    "\n",
    "doc = converter.convert(\"/home/ubuntu/nitish/resume_extractor/data/f32e881949c44afa91794d02dc6c2f46.pdf\").document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "816a5642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"## Nitish Katkade\\n\\n<!-- image -->\\n\\n## Associate Software Engineer\\n\\nnitishkatkade24@gmail.com\\n\\n8799804602\\n\\nPune, India\\n\\nnitishkatkade\\n\\nnitish9413\\n\\n<!-- image -->\\n\\n<!-- image -->\\n\\n## OBJECTIVE\\n\\nProduction-grade backend engineer with 1.5+ years' experience building high-performance data pipelines, GenAI/LLM-based applications, and scalable ML systems. Cut runtime by 99.5% in real-world sensor pipelines, deployed RAG-based document processors, and built ML workflows using FastAPI, LangChain, PySpark, and Databricks. Passionate about GenAI, autonomous agents, and building end-to-end systems that work in the wild.\\n\\n## EDUCATION\\n\\nB. Tech in computer Engineering, Rajarambapu Institute of Technology\\n\\nCGPA: 7.72/10\\n\\n08/2019 - 07/2023 Sangli, India\\n\\n## Skills\\n\\n## Languages\\n\\n## AI/ML\\n\\nPython, JavaScript, TypeScript\\n\\n## Backend/Data\\n\\nFastAPI, SQLAlchemy, Polars, Pandas, Apache NiFi, Airflow\\n\\n## PROFESSIONAL EXPERIENCE\\n\\n## Associate Software Engineer, Kanaka Software\\n\\n- · Cut HVAC sensor pipeline processing time from 30+ hours to 10 minutes by migrating legacy Pandas pipeline to Polars for single-node performance gains.\\n\\nScikit-learn, PyTorch, LangChain, LangGraph, HuggingFace\\n\\n02/2023 - Present Pune, India\\n\\n- · Expanded pipeline scalability by prototyping distributed data processing using PySpark and Databricks notebooks on larger batch workloads. (Note: This shows progression from local optimization to cluster-scale processing.)\\n- · Built and maintained robust Apache NiFi ETL workflows integrated with SQLAlchemy and async DB operations.\\n- · Strengthened error handling, logging, and validation systems, significantly reducing production downtime and failures.\\n\\n## Machine Learning Intern, Ineuron.ai\\n\\n- · Developed an end-to-end ML system to predict insurance premiums using health metrics and Scikit-learn.\\n- · Automated preprocessing and implemented both batch and real-time data pipelines for scalable ML workflows.\\n- · Delivered a high-accuracy PoC with robust ETL for stakeholder demonstrations.\\n\\n03/2022 - 09/2022 Bangalore, India\\n\\n## Polaris HVAC Data Pipeline Optimization,\\n\\nTech: Polars, PySpark, Pandas, NiFi, SQLAlchemy, Databricks, Python, Asyncio\\n\\n- · Migrated legacy Pandas scripts to Polars, reducing runtime by 99.5% for singlenode processing.\\n- · Expanded processing capabilities by prototyping PySpark on Databricks to handle distributed, large-scale batch jobs.\\n- · This dual-tool approach reflects real-world evolution: Polars for fast local runs and PySpark for scaling out.\\n- · Orchestrated full ETL workflows using Apache NiFi with async DB integration.\\n\\n## LLM-Powered Contract Document Processor,\\n\\nTech: FastAPI, LangChain, LangGraph, HuggingFace, Chroma, Ollama, Unstructured\\n\\n- · Built a RAG-based pipeline to extract critical clauses from legal PDF contracts and serve results via API.\\n- · Integrated FastAPI backend with LangChain agents and vector search using Chroma DB.\\n- · Leveraged Unstructured and HuggingFace models to improve NLP accuracy and parsing robustness.\\n\\n## A Comparative Analysis of Weapons Detection Using Various Deep Learning,\\n\\nTechniques\\n\\nTech: YOLOVS, SSD, Faster R-CNN | Published in IEEE Xplore\\n\\n- · Evaluated object detection models on weapons datasets for precision and speed trade-offs.\\n- · Research improved automation in forensic tools and assisted crime scene analysis.\\n\\n## CERTIFICATES &amp; PUBLICATIONS\\n\\nFull Stack Data Science - [Ineuron.ai]\\n\\nA Comparative Analysis of Weapons Detection Using Various Deep Learning Techniques | IEEE | Apr 2023\\n\\n11/2023 - Present\\n\\n04/2022 - 12/2022\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.export_to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fe33149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">## Nitish Katkade\n",
       "\n",
       "<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #000000; text-decoration-color: #000000\">!-- image --&gt;</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">## Associate Software Engineer</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">nitishkatkade24@gmail.com</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8799804602</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">Pune, India</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">nitishkatkade</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">nitish9413</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;!-- image --&gt;</span>\n",
       "\n",
       "<span style=\"color: #000000; text-decoration-color: #000000\">&lt;!-- image --</span><span style=\"font-weight: bold\">&gt;</span>\n",
       "\n",
       "## OBJECTIVE\n",
       "\n",
       "Production-grade backend engineer with <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.5</span>+ years' experience building high-performance data pipelines, \n",
       "GenAI/LLM-based applications, and scalable ML systems. Cut runtime by <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99.5</span>% in real-world sensor pipelines, \n",
       "deployed RAG-based document processors, and built ML workflows using FastAPI, LangChain, PySpark, and Databricks. \n",
       "Passionate about GenAI, autonomous agents, and building end-to-end systems that work in the wild.\n",
       "\n",
       "## EDUCATION\n",
       "\n",
       "B. Tech in computer Engineering, Rajarambapu Institute of Technology\n",
       "\n",
       "CGPA: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7.72</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2019</span> - <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> Sangli, India\n",
       "\n",
       "## Skills\n",
       "\n",
       "## Languages\n",
       "\n",
       "## AI/ML\n",
       "\n",
       "Python, JavaScript, TypeScript\n",
       "\n",
       "## Backend/Data\n",
       "\n",
       "FastAPI, SQLAlchemy, Polars, Pandas, Apache NiFi, Airflow\n",
       "\n",
       "## PROFESSIONAL EXPERIENCE\n",
       "\n",
       "## Associate Software Engineer, Kanaka Software\n",
       "\n",
       "- · Cut HVAC sensor pipeline processing time from <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>+ hours to <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> minutes by migrating legacy Pandas pipeline to \n",
       "Polars for single-node performance gains.\n",
       "\n",
       "Scikit-learn, PyTorch, LangChain, LangGraph, HuggingFace\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> - Present Pune, India\n",
       "\n",
       "- · Expanded pipeline scalability by prototyping distributed data processing using PySpark and Databricks notebooks\n",
       "on larger batch workloads. <span style=\"font-weight: bold\">(</span>Note: This shows progression from local optimization to cluster-scale processing.<span style=\"font-weight: bold\">)</span>\n",
       "- · Built and maintained robust Apache NiFi ETL workflows integrated with SQLAlchemy and async DB operations.\n",
       "- · Strengthened error handling, logging, and validation systems, significantly reducing production downtime and \n",
       "failures.\n",
       "\n",
       "## Machine Learning Intern, Ineuron.ai\n",
       "\n",
       "- · Developed an end-to-end ML system to predict insurance premiums using health metrics and Scikit-learn.\n",
       "- · Automated preprocessing and implemented both batch and real-time data pipelines for scalable ML workflows.\n",
       "- · Delivered a high-accuracy PoC with robust ETL for stakeholder demonstrations.\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2022</span> - <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2022</span> Bangalore, India\n",
       "\n",
       "## Polaris HVAC Data Pipeline Optimization,\n",
       "\n",
       "Tech: Polars, PySpark, Pandas, NiFi, SQLAlchemy, Databricks, Python, Asyncio\n",
       "\n",
       "- · Migrated legacy Pandas scripts to Polars, reducing runtime by <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99.5</span>% for singlenode processing.\n",
       "- · Expanded processing capabilities by prototyping PySpark on Databricks to handle distributed, large-scale batch \n",
       "jobs.\n",
       "- · This dual-tool approach reflects real-world evolution: Polars for fast local runs and PySpark for scaling out.\n",
       "- · Orchestrated full ETL workflows using Apache NiFi with async DB integration.\n",
       "\n",
       "## LLM-Powered Contract Document Processor,\n",
       "\n",
       "Tech: FastAPI, LangChain, LangGraph, HuggingFace, Chroma, Ollama, Unstructured\n",
       "\n",
       "- · Built a RAG-based pipeline to extract critical clauses from legal PDF contracts and serve results via API.\n",
       "- · Integrated FastAPI backend with LangChain agents and vector search using Chroma DB.\n",
       "- · Leveraged Unstructured and HuggingFace models to improve NLP accuracy and parsing robustness.\n",
       "\n",
       "## A Comparative Analysis of Weapons Detection Using Various Deep Learning,\n",
       "\n",
       "Techniques\n",
       "\n",
       "Tech: YOLOVS, SSD, Faster R-CNN | Published in IEEE Xplore\n",
       "\n",
       "- · Evaluated object detection models on weapons datasets for precision and speed trade-offs.\n",
       "- · Research improved automation in forensic tools and assisted crime scene analysis.\n",
       "\n",
       "## CERTIFICATES &amp;amp; PUBLICATIONS\n",
       "\n",
       "Full Stack Data Science - <span style=\"font-weight: bold\">[</span>Ineuron.ai<span style=\"font-weight: bold\">]</span>\n",
       "\n",
       "A Comparative Analysis of Weapons Detection Using Various Deep Learning Techniques | IEEE | Apr <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span> - Present\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">04</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2022</span> - <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2022</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "## Nitish Katkade\n",
       "\n",
       "\u001b[1m<\u001b[0m\u001b[39m!-- image -->\u001b[0m\n",
       "\n",
       "\u001b[39m## Associate Software Engineer\u001b[0m\n",
       "\n",
       "\u001b[39mnitishkatkade24@gmail.com\u001b[0m\n",
       "\n",
       "\u001b[1;36m8799804602\u001b[0m\n",
       "\n",
       "\u001b[39mPune, India\u001b[0m\n",
       "\n",
       "\u001b[39mnitishkatkade\u001b[0m\n",
       "\n",
       "\u001b[39mnitish9413\u001b[0m\n",
       "\n",
       "\u001b[39m<!-- image -->\u001b[0m\n",
       "\n",
       "\u001b[39m<!-- image --\u001b[0m\u001b[1m>\u001b[0m\n",
       "\n",
       "## OBJECTIVE\n",
       "\n",
       "Production-grade backend engineer with \u001b[1;36m1.5\u001b[0m+ years' experience building high-performance data pipelines, \n",
       "GenAI/LLM-based applications, and scalable ML systems. Cut runtime by \u001b[1;36m99.5\u001b[0m% in real-world sensor pipelines, \n",
       "deployed RAG-based document processors, and built ML workflows using FastAPI, LangChain, PySpark, and Databricks. \n",
       "Passionate about GenAI, autonomous agents, and building end-to-end systems that work in the wild.\n",
       "\n",
       "## EDUCATION\n",
       "\n",
       "B. Tech in computer Engineering, Rajarambapu Institute of Technology\n",
       "\n",
       "CGPA: \u001b[1;36m7.72\u001b[0m/\u001b[1;36m10\u001b[0m\n",
       "\n",
       "\u001b[1;36m08\u001b[0m/\u001b[1;36m2019\u001b[0m - \u001b[1;36m07\u001b[0m/\u001b[1;36m2023\u001b[0m Sangli, India\n",
       "\n",
       "## Skills\n",
       "\n",
       "## Languages\n",
       "\n",
       "## AI/ML\n",
       "\n",
       "Python, JavaScript, TypeScript\n",
       "\n",
       "## Backend/Data\n",
       "\n",
       "FastAPI, SQLAlchemy, Polars, Pandas, Apache NiFi, Airflow\n",
       "\n",
       "## PROFESSIONAL EXPERIENCE\n",
       "\n",
       "## Associate Software Engineer, Kanaka Software\n",
       "\n",
       "- · Cut HVAC sensor pipeline processing time from \u001b[1;36m30\u001b[0m+ hours to \u001b[1;36m10\u001b[0m minutes by migrating legacy Pandas pipeline to \n",
       "Polars for single-node performance gains.\n",
       "\n",
       "Scikit-learn, PyTorch, LangChain, LangGraph, HuggingFace\n",
       "\n",
       "\u001b[1;36m02\u001b[0m/\u001b[1;36m2023\u001b[0m - Present Pune, India\n",
       "\n",
       "- · Expanded pipeline scalability by prototyping distributed data processing using PySpark and Databricks notebooks\n",
       "on larger batch workloads. \u001b[1m(\u001b[0mNote: This shows progression from local optimization to cluster-scale processing.\u001b[1m)\u001b[0m\n",
       "- · Built and maintained robust Apache NiFi ETL workflows integrated with SQLAlchemy and async DB operations.\n",
       "- · Strengthened error handling, logging, and validation systems, significantly reducing production downtime and \n",
       "failures.\n",
       "\n",
       "## Machine Learning Intern, Ineuron.ai\n",
       "\n",
       "- · Developed an end-to-end ML system to predict insurance premiums using health metrics and Scikit-learn.\n",
       "- · Automated preprocessing and implemented both batch and real-time data pipelines for scalable ML workflows.\n",
       "- · Delivered a high-accuracy PoC with robust ETL for stakeholder demonstrations.\n",
       "\n",
       "\u001b[1;36m03\u001b[0m/\u001b[1;36m2022\u001b[0m - \u001b[1;36m09\u001b[0m/\u001b[1;36m2022\u001b[0m Bangalore, India\n",
       "\n",
       "## Polaris HVAC Data Pipeline Optimization,\n",
       "\n",
       "Tech: Polars, PySpark, Pandas, NiFi, SQLAlchemy, Databricks, Python, Asyncio\n",
       "\n",
       "- · Migrated legacy Pandas scripts to Polars, reducing runtime by \u001b[1;36m99.5\u001b[0m% for singlenode processing.\n",
       "- · Expanded processing capabilities by prototyping PySpark on Databricks to handle distributed, large-scale batch \n",
       "jobs.\n",
       "- · This dual-tool approach reflects real-world evolution: Polars for fast local runs and PySpark for scaling out.\n",
       "- · Orchestrated full ETL workflows using Apache NiFi with async DB integration.\n",
       "\n",
       "## LLM-Powered Contract Document Processor,\n",
       "\n",
       "Tech: FastAPI, LangChain, LangGraph, HuggingFace, Chroma, Ollama, Unstructured\n",
       "\n",
       "- · Built a RAG-based pipeline to extract critical clauses from legal PDF contracts and serve results via API.\n",
       "- · Integrated FastAPI backend with LangChain agents and vector search using Chroma DB.\n",
       "- · Leveraged Unstructured and HuggingFace models to improve NLP accuracy and parsing robustness.\n",
       "\n",
       "## A Comparative Analysis of Weapons Detection Using Various Deep Learning,\n",
       "\n",
       "Techniques\n",
       "\n",
       "Tech: YOLOVS, SSD, Faster R-CNN | Published in IEEE Xplore\n",
       "\n",
       "- · Evaluated object detection models on weapons datasets for precision and speed trade-offs.\n",
       "- · Research improved automation in forensic tools and assisted crime scene analysis.\n",
       "\n",
       "## CERTIFICATES &amp; PUBLICATIONS\n",
       "\n",
       "Full Stack Data Science - \u001b[1m[\u001b[0mIneuron.ai\u001b[1m]\u001b[0m\n",
       "\n",
       "A Comparative Analysis of Weapons Detection Using Various Deep Learning Techniques | IEEE | Apr \u001b[1;36m2023\u001b[0m\n",
       "\n",
       "\u001b[1;36m11\u001b[0m/\u001b[1;36m2023\u001b[0m - Present\n",
       "\n",
       "\u001b[1;36m04\u001b[0m/\u001b[1;36m2022\u001b[0m - \u001b[1;36m12\u001b[0m/\u001b[1;36m2022\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print\n",
    "print(doc.export_to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4ac9d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents.base import Document\n",
    "from langchain_docling import DoclingLoader\n",
    "from langchain_docling.loader import ExportType\n",
    "from docling.chunking import HybridChunker\n",
    "\n",
    "EMBED_MODEL_ID = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "EXPORT_TYPE = ExportType.MARKDOWN\n",
    "\n",
    "\n",
    "def get_document_loader(file_path) -> DoclingLoader:\n",
    "    loader: DoclingLoader = DoclingLoader(\n",
    "        file_path=file_path,\n",
    "        export_type=EXPORT_TYPE,\n",
    "        chunker=HybridChunker(tokenizer=EMBED_MODEL_ID),\n",
    "    )\n",
    "    return loader\n",
    "\n",
    "def get_extracted_document(file_path):\n",
    "    loader = get_document_loader(file_path)\n",
    "\n",
    "    docs: list[Document] = loader.load()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb5634a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = get_extracted_document(\"/home/ubuntu/nitish/resume_extractor/data/f32e881949c44afa91794d02dc6c2f46.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42fe71ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"/home/ubuntu/nitish/resume_extractor/data/f32e881949c44afa91794d02dc6c2f46.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6df19091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.datamodel import vlm_model_specs\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    VlmPipelineOptions,\n",
    ")\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.pipeline.vlm_pipeline import VlmPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dcd91cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_cls=VlmPipeline,\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "539c3f66",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m doc = \u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m.document\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nitish/resume_extractor/.venv/lib/python3.12/site-packages/pydantic/_internal/_validate_call.py:39\u001b[39m, in \u001b[36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(wrapped)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_function\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nitish/resume_extractor/.venv/lib/python3.12/site-packages/pydantic/_internal/_validate_call.py:136\u001b[39m, in \u001b[36mValidateCallWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__pydantic_complete__:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28mself\u001b[39m._create_validators()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydantic_core\u001b[49m\u001b[43m.\u001b[49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nitish/resume_extractor/.venv/lib/python3.12/site-packages/docling/document_converter.py:235\u001b[39m, in \u001b[36mDocumentConverter.convert\u001b[39m\u001b[34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;129m@validate_call\u001b[39m(config=ConfigDict(strict=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert\u001b[39m(\n\u001b[32m    219\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    225\u001b[39m     page_range: PageRange = DEFAULT_PAGE_RANGE,\n\u001b[32m    226\u001b[39m ) -> ConversionResult:\n\u001b[32m    227\u001b[39m     all_res = \u001b[38;5;28mself\u001b[39m.convert_all(\n\u001b[32m    228\u001b[39m         source=[source],\n\u001b[32m    229\u001b[39m         raises_on_error=raises_on_error,\n\u001b[32m   (...)\u001b[39m\u001b[32m    233\u001b[39m         page_range=page_range,\n\u001b[32m    234\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_res\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nitish/resume_extractor/.venv/lib/python3.12/site-packages/docling/document_converter.py:258\u001b[39m, in \u001b[36mDocumentConverter.convert_all\u001b[39m\u001b[34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[39m\n\u001b[32m    255\u001b[39m conv_res_iter = \u001b[38;5;28mself\u001b[39m._convert(conv_input, raises_on_error=raises_on_error)\n\u001b[32m    257\u001b[39m had_result = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res_iter\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhad_result\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConversionStatus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSUCCESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConversionStatus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPARTIAL_SUCCESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nitish/resume_extractor/.venv/lib/python3.12/site-packages/docling/document_converter.py:293\u001b[39m, in \u001b[36mDocumentConverter._convert\u001b[39m\u001b[34m(self, conv_input, raises_on_error)\u001b[39m\n\u001b[32m    284\u001b[39m _log.info(\u001b[33m\"\u001b[39m\u001b[33mGoing to convert document batch...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    286\u001b[39m \u001b[38;5;66;03m# parallel processing only within input_batch\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;66;03m# with ThreadPoolExecutor(\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;66;03m#    max_workers=settings.perf.doc_batch_concurrency\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[38;5;66;03m# ) as pool:\u001b[39;00m\n\u001b[32m    290\u001b[39m \u001b[38;5;66;03m#   yield from pool.map(self.process_document, input_batch)\u001b[39;00m\n\u001b[32m    291\u001b[39m \u001b[38;5;66;03m# Note: PDF backends are not thread-safe, thread pool usage was disabled.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_document\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43melapsed\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmonotonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmonotonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nitish/resume_extractor/.venv/lib/python3.12/site-packages/docling/document_converter.py:339\u001b[39m, in \u001b[36mDocumentConverter._process_document\u001b[39m\u001b[34m(self, in_doc, raises_on_error)\u001b[39m\n\u001b[32m    335\u001b[39m valid = (\n\u001b[32m    336\u001b[39m     \u001b[38;5;28mself\u001b[39m.allowed_formats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m in_doc.format \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.allowed_formats\n\u001b[32m    337\u001b[39m )\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m     conv_res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    341\u001b[39m     error_message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile format not allowed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_doc.file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nitish/resume_extractor/.venv/lib/python3.12/site-packages/docling/document_converter.py:360\u001b[39m, in \u001b[36mDocumentConverter._execute_pipeline\u001b[39m\u001b[34m(self, in_doc, raises_on_error)\u001b[39m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_execute_pipeline\u001b[39m(\n\u001b[32m    357\u001b[39m     \u001b[38;5;28mself\u001b[39m, in_doc: InputDocument, raises_on_error: \u001b[38;5;28mbool\u001b[39m\n\u001b[32m    358\u001b[39m ) -> ConversionResult:\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m in_doc.valid:\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m         pipeline = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_doc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    361\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m pipeline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    362\u001b[39m             conv_res = pipeline.execute(in_doc, raises_on_error=raises_on_error)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nitish/resume_extractor/.venv/lib/python3.12/site-packages/docling/document_converter.py:322\u001b[39m, in \u001b[36mDocumentConverter._get_pipeline\u001b[39m\u001b[34m(self, doc_format)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache_key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.initialized_pipelines:\n\u001b[32m    319\u001b[39m     _log.info(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInitializing pipeline for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline_class.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with options hash \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptions_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     \u001b[38;5;28mself\u001b[39m.initialized_pipelines[cache_key] = \u001b[43mpipeline_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpipeline_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpipeline_options\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    326\u001b[39m     _log.debug(\n\u001b[32m    327\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReusing cached pipeline for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline_class.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with options hash \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptions_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    328\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nitish/resume_extractor/.venv/lib/python3.12/site-packages/docling/pipeline/vlm_pipeline.py:99\u001b[39m, in \u001b[36mVlmPipeline.__init__\u001b[39m\u001b[34m(self, pipeline_options)\u001b[39m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28mself\u001b[39m.build_pipe = [\n\u001b[32m     90\u001b[39m         HuggingFaceMlxModel(\n\u001b[32m     91\u001b[39m             enabled=\u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# must be always enabled for this pipeline to make sense.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     95\u001b[39m         ),\n\u001b[32m     96\u001b[39m     ]\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m vlm_options.inference_framework == InferenceFramework.TRANSFORMERS:\n\u001b[32m     98\u001b[39m     \u001b[38;5;28mself\u001b[39m.build_pipe = [\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m         \u001b[43mHuggingFaceTransformersVlmModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m            \u001b[49m\u001b[43menabled\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# must be always enabled for this pipeline to make sense.\u001b[39;49;00m\n\u001b[32m    101\u001b[39m \u001b[43m            \u001b[49m\u001b[43martifacts_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifacts_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m            \u001b[49m\u001b[43maccelerator_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpipeline_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccelerator_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvlm_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvlm_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    105\u001b[39m     ]\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    108\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not instantiate the right type of VLM pipeline: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvlm_options.inference_framework\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    109\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nitish/resume_extractor/.venv/lib/python3.12/site-packages/docling/models/vlm_models_inline/hf_transformers_model.py:99\u001b[39m, in \u001b[36mHuggingFaceTransformersVlmModel.__init__\u001b[39m\u001b[34m(self, enabled, artifacts_path, accelerator_options, vlm_options)\u001b[39m\n\u001b[32m     93\u001b[39m     model_cls = AutoModelForVision2Seq\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m.processor = AutoProcessor.from_pretrained(\n\u001b[32m     96\u001b[39m     artifacts_path,\n\u001b[32m     97\u001b[39m     trust_remote_code=vlm_options.trust_remote_code,\n\u001b[32m     98\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m \u001b[38;5;28mself\u001b[39m.vlm_model = \u001b[43mmodel_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43martifacts_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvlm_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_attn_implementation\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mflash_attention_2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    105\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43maccelerator_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda_use_flash_attention2\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meager\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    108\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvlm_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# Load generation config\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[38;5;28mself\u001b[39m.generation_config = GenerationConfig.from_pretrained(artifacts_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nitish/resume_extractor/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:600\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    599\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m600\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    604\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    605\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    606\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nitish/resume_extractor/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:311\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    309\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    313\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/nitish/resume_extractor/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:4540\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4538\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDeepSpeed Zero-3 is not compatible with passing a `device_map`.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4539\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[32m-> \u001b[39m\u001b[32m4540\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   4541\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mUsing a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4542\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mrequires `accelerate`. You can install it with `pip install accelerate`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4543\u001b[39m         )\n\u001b[32m   4545\u001b[39m \u001b[38;5;66;03m# handling bnb config from kwargs, remove after `load_in_{4/8}bit` deprecation.\u001b[39;00m\n\u001b[32m   4546\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m load_in_4bit \u001b[38;5;129;01mor\u001b[39;00m load_in_8bit:\n",
      "\u001b[31mValueError\u001b[39m: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`"
     ]
    }
   ],
   "source": [
    "doc = converter.convert(source=source).document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e8b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc.export_to_markdown())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume_extractor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
